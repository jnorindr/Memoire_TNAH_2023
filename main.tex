\documentclass[a4paper,12pt,twoside]{book}
\usepackage[T1]{fontenc}
\usepackage{inputenc}
\usepackage{fontspec}
\usepackage{lmodern}
\usepackage[english,french]{babel}
\usepackage{xspace} % pour la gestion des espaces après les commandes
%\usepackage{minted} % colored source code
\usepackage{csquotes} % Gestion des guillemets dans la biblio
\usepackage[xetex]{graphicx} %Package pour gérer les images
\usepackage{caption}
\usepackage{subcaption}
\usepackage{float} %Gestion de la position des images

\usepackage{hyperref}
\hypersetup{%
	pdfusetitle, 
	pdfauthor={Jade Norindr}
	pdfsubject={Mémoire TNAH — Le traitement des sources historiques par la vision artificielle}, 
	pdfkeywords={vision artificielle}
}

% Mise en page École des chartes
\usepackage[margin=2.5cm]{geometry} % marges
\usepackage{setspace}
\onehalfspacing % interligne de 1.5
\setlength\parindent{1cm}

\usepackage{tocbibind}
\usepackage[backend=biber, sorting=nyt, style=enc]{biblatex}
\addbibresource{bibliographie/bibliographie.bib}
%\nocite{*}
\defbibnote{intro}{Cette bibliographie présente toutes les ressources utilisées, de tout type, citées ou non, par simple ordre alphabétique.}


\author{Jade Norindr – M2 TNAH — ENC}
\title{Le traitement des sources historiques par la vision artificielle. L'exemple des manuscrits d'astronomie de tradition ptoléméenne}

% Acronymes
\usepackage[automake, acronym, toc]{glossaries}
\makeglossaries

\setacronymstyle{short-long}
\newacronym{api}{\textsc{api}}{\emph{Application Programming Interface}}
\newacronym{eida}{\textsc{eida}}{\emph{Editing and analysing hIstorical astronomical Diagrams with Artificial intelligence}}
\newacronym{dishas}{\textsc{dishas}}{\emph{Digital Information System for the History of Astral Sciences}}
\newacronym{dti}{\textsc{dti}}{\emph{DISHAS Table Interface}}
\newacronym{dips}{\textsc{dips}}{\emph{DISHAS Interactive Parameter Squeezer}}
\newacronym{xml}{\textsc{xml}}{\emph{eXtensible Markup Language}}
\newacronym{csv}{\textsc{csv}}{\emph{Comma-separated values}}
\newacronym{html}{\textsc{html}}{\emph{HyperText Markup Language}}
\newacronym{htr}{\textsc{htr}}{\emph{Handwritten Text Recognition}}
\newacronym{imagine}{\textsc{imagine}}{Laboratoire d’Informatique Gaspard Monge}
\newacronym{vhs}{\textsc{vhs}}{Vision artificielle et analyse Historique de la circulation de l'illustration Scientifique}
\newacronym{syrte}{\textsc{syrte}}{Systèmes de Référence Temps-Espace}
\newacronym{iscd}{\textsc{iscd}}{Institut des sciences du calcul et des données}
\newacronym{bnf}{BnF}{Bibliothèque nationale de France}
\newacronym{inha}{\textsc{inha}}{Institut national d'histoire de l'art}
\newacronym{rmn}{Rmn-Grand Palais}{Réunion des musées nationaux-Grand Palais}
\newacronym{iiif}{\textsc{iiif}}{\emph{International Image Interoperability Framework}}
\newacronym{http}{\textsc{http}}{\emph{Hypertext Transfer Protocol}}
\newacronym{https}{\textsc{https}}{\emph{Hypertext Transfer Protocol Secure}}
\newacronym{uri}{\textsc{uri}}{\emph{Uniform Resource Identifier}}
\newacronym{json}{\textsc{json}}{\emph{JavaScript Object Notation}}
\newacronym{svg}{\textsc{svg}}{\emph{Scalable Vector Graphics}}
\newacronym{enherit}{EnHerit}{\emph{Enhancing Heritage Image Databases}}
\newacronym{cnn}{\textsc{cnn}}{Convolutional Neural Nets}
\newacronym{yolo}{\textsc{yolo}}{\textit{You Only Look Once}}
% Acronymes en petites capitales dans la liste des acronymes
\usepackage{enumitem}
\setlist[description]{labelwidth=2em, labelsep=.5em, font=\normalfont}

% Commandes
\newcommand{\yolo}{\gls{yolo}\xspace}
\newcommand{\yolov}{\textsc{yolo}v5\xspace}
\newcommand{\docex}{docExtractor\xspace}
\newcommand{\cnn}{\gls{cnn}\xspace}
\newcommand{\imagine}{\gls{imagine}\xspace}
\newcommand{\enherit}{\gls{enherit}\xspace}
\newcommand{\svg}{\gls{svg}\xspace}
\newcommand{\json}{\gls{json}\xspace}
\newcommand{\bnf}{\gls{bnf}\xspace}
\newcommand{\uri}{\gls{uri}\xspace}
\newcommand{\iiif}{\gls{iiif}\xspace}
\newcommand{\http}{\gls{http}\xspace}
\newcommand{\https}{\gls{https}\xspace}
\newcommand{\inha}{\gls{inha}\xspace}
\newcommand{\enc}{École nationale des chartes\xspace}
\newcommand{\ponts}{École des Ponts ParisTech\xspace}
\newcommand{\api}{\gls{api}\xspace}
\newcommand{\eida}{\gls{eida}\xspace}
\newcommand{\vhs}{\gls{vhs}\xspace}
\newcommand{\dishas}{\gls{dishas}\xspace}
\newcommand{\ist}{\textsc{i}\ieme{}\xspace}
\newcommand{\ii}{\textsc{ii}\ieme{}\xspace}
\newcommand{\viii}{\textsc{viii}\ieme{}\xspace}
\newcommand{\ix}{\textsc{ix}\ieme{}\xspace}
\newcommand{\xie}{\textsc{xi}\ieme{}\xspace}
\newcommand{\xii}{\textsc{xii}\ieme{}\xspace}
\newcommand{\xiii}{\textsc{xiii}\ieme{}\xspace}
\newcommand{\xv}{\textsc{xv}\ieme{}\xspace}
\newcommand{\xvi}{\textsc{xvi}\ieme{}\xspace}
\newcommand{\xviii}{\textsc{xviii}\ieme{}\xspace}
\newcommand{\ml}{\textit{machine learning}\xspace}
\newcommand{\dl}{\textit{deep learning}\xspace}
\newcommand{\cv}{\textit{computer vision}\xspace}
\newcommand{\jc}{av. J.-C.\xspace}
\newcommand{\ma}{Moyen-Âge\xspace}
\newcommand{\ia}{intelligence artificielle\xspace}

\newcommand{\clearemptydoublepage}{\newpage{\pagestyle{empty}\cleardoublepage}}
% Pour des chapitres non numérotées dans la table des matière
\newcommand\chapterNo[1]{
  \chapter*{#1}
  \markright{\MakeUppercase{#1}}
}

\begin{document}

\onehalfspacing 

\frontmatter

    \include{templates/page-titre}

    \thispagestyle{empty}	
    \cleardoublepage
	
    \include{templates/resume}
	
    \chapterNo{Remerciements}
    \addcontentsline{toc}{chapter}{Remerciements}

    \printbibliography

    \chapterNo{Introduction}
    \addcontentsline{toc}{chapter}{Introduction}

    \thispagestyle{empty}
    \cleardoublepage

\mainmatter

    \part{Construire un corpus de numérisations pour le traitement par vision artificielle}
        \chapter{Le projet EiDA}
        Cette partie a pour objectif de revenir sur le contexte institutionnel du projet \eida, projet de recherche mené à l'Observatoire de Paris par l'équipe d'histoire des science du laboratoire \acrshort{syrte}. Ce projet a pour sujet d'étude les diagrammes astronomiques de tradition ptoléméenne : cette partie vise ainsi à contextualiser d'un point de vue historique le corpus du projet, et à en expliciter les bornes chronologiques et géographiques.
        
                \section{Contexte et objectifs du projet}
                    \input{templates/partie1/chap1/section1}

                \section{Sources primaires}
                    \input{templates/partie1/chap1/section2}
		\\
		
		\eida est un projet aux bornes chronologiques, géographiques et thématiques vastes, pour permettre une étude sur un temps long et dans un contexte global de la circulation des diagrammes astronomiques et des théories scientifiques qui les accompagnent. Dans cette démarche, proposer une étude quantitative, traitant un grand nombre de sources, permet de mettre en avant des motifs, connexions et évolutions en accord avec la diffusion afro-eurasienne des idées développées par Ptolémée. Les bornes définies dans cette partie permettent de délimiter un corpus d'images -- numérisations d'ouvrages manuscrits ou imprimés -- qui en tant d'objets numériques présentent également leurs propres problématiques, sur lesquelles revient la partie suivante.
        \clearemptydoublepage
        
        \chapter{Images et interopérabilité}
        Les sources étudiées dans ce mémoire sont des sources iconographiques : cette partie vise à revenir sur les formats, ressources et méthodes pour le traitement des images en ligne, de la production de la ressource à sa publication. Les images digitales présentent des enjeux spécifiques, du point de vue de la technique, du droit et de la disponibilité. La mise en ligne et la diffusion d'une image fait suite à une longue chaîne de traitement qui a pour point de départ un objet matériel, et soulève des questionnements divers. Les spécifications \iiif tente de répondre à un certain nombre de problématiques liées à la présence en ligne de ressources iconographiques, et cette partie vise donc à présenter les solutions, possibilités et limites offertes par ce standard.
        
                \section{L’image comme source}
                    \input{templates/partie1/chap2/section1}
            
                \section{Le standard IIIF}
                    \input{templates/partie1/chap2/section2}
        \\
        
        Les sources iconographiques sont soumises à un ensemble de restrictions, du point de vue du format, des métadonnées ou des droits, qui manquent encore d'une uniformité internationale et entre institutions qui rendrait fluide le partage de ces ressources sur Internet et entre les projets de recherche. Dans un projet impliquant l'utilisation d'algorithmes de vision artificielle, qui repose alors sur le traitement d'un volume important d'image, la mise en ligne de ces documents est un enjeux crucial, sur lequel repose d'une part la possibilité de constituer un corpus exploitable, ainsi que la publication des résultats du projet, qui peuvent également prendre la forme d'images numériques. Dans une optique de science ouverte, l'utilisation de standards et d'outils tels que ceux développés par le consortium \iiif permet d'assurer le partage d'images et de données respectant les mêmes formats, exploitables avec des outils libres, et d'avancer vers une abolition des silos de données, qui faciliterait notamment la construction de corpus massifs pour l'apprentissage machine. 
        \clearemptydoublepage
        
        \chapter[Corpus historiques et jeux de données]{Corpus historiques et jeux de données pour l’apprentissage machine}
        
        La vision artificielle et l'apprentissage machine permet le traitement de corpus d'images massifs par des méthodes quantitatives qui permettent aux historiens de traiter un volume de données bien plus important qu'une approche manuelle, ouvrant ainsi la voie à de nouvelles approches. Cette partie revient sur les bonnes pratiques à mettre en place afin d'assurer la pertinence de l'utilisation de ces outils, et d'en faire des traitements efficaces en accord avec les ambitions des projets.
        
                \section{Dimensions et cadre}
                    \input{templates/partie1/chap3/section1}
            
                \section{Objectifs scientifiques et possibilités numériques}
                    \input{templates/partie1/chap3/section2}
        \\
        
        Le \dl et la vision artificielle permettent aux projets de recherche en histoire et en histoire de l'art d'envisager de nouvelles approches des sources, à l'aide de traitement automatisés qui offrent de nouvelles méthodes de navigation de corpus d'images massifs : de la détection à l'édition, les outils produits redéfinissent les étapes de traitement des sources, et il est ainsi nécessaire d'intégrer aux pratiques des chercheurs des méthodes spécifiques à ce type d'approche, et notamment pour la création de jeu de données d'entraînement, à la base du développement de tout modèle de \ml. Cette intégration passe notamment par la rédaction de documentation, ainsi qu'un dialogue entre les équipes de recherche en vision artificielle et les équipes d'historiens. Ce dialogue permet d'établir les besoins de chacun, et de développer des outils techniques qui répondent aux besoins scientifiques de manière pertinente, en développant des modèles qui, malgré leurs limites, rejoignent aux mieux les attentes des sciences historiques.
        \clearemptydoublepage


    \part{De l’image à l’objet : intégrer l’apprentissage profond au traitement des sources historiques}
        \chapter[L'apprentissage profond]{Principes et utilisation de l’apprentissage profond}
        
        L'apprentissage profond est un sous-domaine de l'apprentissage automatique basé sur l'apprentissage de couches successives de représentation. Le nombre de couches définit la profondeur du modèle : de nos jours, l'apprentissage profond compte plusieurs dizaines à plusieurs centaines de couches, qui apprennent toutes automatiquement à l'aide de données d'apprentissage\footcite{cholletApprentissageProfondAvec2020a}. Cette approche est au cœur des modèles de vision artificielle dont nous parlons dans ce mémoire, qui reposent sur des réseaux de neurones qui constituent ces couches superposées permettant un apprentissage des représentations à partir de données fournies.
        
                \section{Réseaux de neurones et \textit{computer vision}}
                    \input{templates/partie2/chap4/section1}
            
                \section[Modèles de vision \textit{off-the-shelf}]{Modèles de détection \textit{off-the-shelf} : outils libres pour l'extraction d’objets}
                    \input{templates/partie2/chap4/section2}
        \\
		
		Les modèles de vision \textit{off-the-shelf} ouvrent à des projets divers la possibilité d'intégrer la vision artificielle à leurs méthodologies, en réduisant le coût humain et temporel du développement d'un modèle de \textit{deep learning} par la mise à disposition en accès libre d'outils déjà performants, qu'il est possible d'entraîner pour les ajuster à des données spécifiques. Pour la détection d'objets, des jeux de données en accès libre tels qu'ImageNet permettent un pré-entraînement de ces modèles \textit{off-the-shelf}, qui apprennent alors des caractéristiques larges qui peuvent être précisées par un entraînement sur des sources plus spécifiques, en nécessitant un volume de données moins important qu'un modèle créé de zéro : ces modèles de détection \textit{off-the-shelf} présentent ainsi une solution aux limites que peuvent présenter les sources historiques en termes de volume des données disponibles, et permettent également aux projets de se construire sur des bases solides, sans allouer de ressources à la création d'outils déjà existants, déjà performants, pour des tâches telles que la détection d'objet qui font partie des tâches canoniques de la vision par ordinateur.
        \clearemptydoublepage
        
        \chapter[L’interface entre chercheurs et algorithme]{L’interface entre chercheurs et algorithmes : construire une plateforme pour la détection}
                \section[Architecture de l’application]{Architecture de l’application : fonctionnalités et outils}
                    \input{templates/partie2/chap5/section1}
                    
                \section{Créer un outil open source : penser une application réutilisable}
            		\input{templates/partie2/chap5/section2}
            
        \clearemptydoublepage
        
        \chapter[\textit{Deep learning} et pratiques des chercheurs]{Intégrer l’apprentissage profond aux pratiques des chercheurs : le \textit{workflow} de traitement des sources}
                \section{Annoter sur un GPU : extractorAPI}
                    \input{templates/partie2/chap6/section1}
            
                \section{De la numérisation à l’annotation}
                    \input{templates/partie2/chap6/section2}
             
                \section{Médiation et documentation}
                    \input{templates/partie2/chap6/section3}
            
        \clearemptydoublepage

    \part{Perspectives pour le traitement des sources : vers un outil pour l’édition et la recherche}
        \chapter[Éditer des diagrammes]{Éditer des diagrammes : vectorisation et édition critique}
                \section{Édition critique des diagrammes astronomiques}
                    \input{templates/partie3/chap7/section1}
            
                \section[De l’image aux vecteurs]{De l’image aux vecteurs : la vision artificielle pour l’édition numérique}
                    \input{templates/partie3/chap7/section2}
            
        \clearemptydoublepage
        
        \chapter{Regroupement par similarité et \textit{clustering}}
                \section{\textit{Similarity retrieval} et navigation des corpus}
                    \input{templates/partie3/chap8/section1}
            
                \section{Le \textit{clustering} comme outil pour les chercheurs}
                    \input{templates/partie3/chap8/section2}
            
        \clearemptydoublepage
        
        \chapter[Exploiter les résultats automatique]{Étudier et exploiter les résultats automatiques : limites et perspectives pour les sciences historiques}
                \section{Titre section 1}
                    \input{templates/partie3/chap9/section1}
            
                \section{Titre section 2}
                    \input{templates/partie3/chap9/section2}
            
        \clearemptydoublepage
    
    \chapterNo{Conclusion}
    \addcontentsline{toc}{chapter}{Conclusion}

\appendix
    \part*{Annexes}	
    \addcontentsline{toc}{part}{Annexes}
    
    \chapter[Prepare custom data for training]{\label{YOLOv5Training}Prepare custom data for training using the YOLOv5 workflow}
    \input{templates/annexes/yolotraining}

\clearemptydoublepage

\backmatter
    \printacronyms[title=Liste des acronymes,toctitle=Acronymes]
    \printglossary 
    \tableofcontents
	
\end{document}