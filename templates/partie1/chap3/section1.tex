% Dimensions et cadre

\subsection{La tentative de l’exhaustivité}
    \subsubsection{Représentativité et pertinence}
L'approche computationnelle de corpus de sources historiques permet le traitement d'un volume d'images inenvisageable sans automatisation, qui redéfinit ainsi le rôle des chercheurs comme les méthodes de constitution d'un corpus, pour prendre en compte cette quantité de données qu'il est possible de considérer à l'aide d'outils numériques\footcite{klinkeBigImageData2016}. L'apprentissage profond permet d'envisager une redéfinition des méthodes des historiens et historiens de l'art, en intégrant une part d'automatisation dans le traitement des sources iconographiques, permettant ainsi d'envisager l'exploration de corpus bien plus vastes\footcite{moiraghiExplorerCorpusImages2018} par des méthodes quantitatives\footcite{klinkeBigImageData2016}.

Dans le cadre du projet \eida, ces possibilités ouvertes par l'intégration de techniques de vision artificielle dans le traitement du corpus permet ainsi d'envisager des bornes larges, définies précédemment, sur le plan géographique comme chronologique, tout en assurant un traitement d'un grand nombre de sources -- plusieurs centaines ou milliers d'images -- pour chaque contexte étudié. 

Le projet \vhs s'appuie également grandement sur la vision artificielle appliquée à la détection de similarité, dans le cadre d'une étude de la circulation des savoirs scientifiques par le bais de l'illustration : les corpus constitués pour le projet ont donc été pensés pour offrir un regard pertinent sur ces questions, et sélectionnés avec une volonté de représentativité géographique, chronologique et thématique\footcite{Corpus}. Leur analyse portera ainsi sur un ensemble de plus de 10000 images d'animaux, de plantes et de minéraux.

Ainsi, l'intégration au cadre des projets de méthodes de vision artificielle permet d'envisager l'étude de corpus larges, vastes, et de porter un regard sur des zones géographiques larges, sur des périodes étendues, avec la possibilité de traiter des corpus massifs par des approches quantitatives développées en collaboration avec les historiens.

    \subsubsection{Données d'entraînement}
Au-delà de la pertinence du corpus pour un projet de recherche donné, il est nécessaire, pour l'entraînement d'un modèle de vision artificielle, de prévoir un fragment du corpus dédié à la constitution d'un ou de plusieurs jeux de données d'entraînement\footnote{Un jeu de données d'entraînement comptant en général plusieurs centaines d'exemples, il est possible, à cette étape, d'évaluer la pertinence véritable du développement d'un modèle dédié au traitement du corpus global du projet. \cite{strienComputerVisionHumanities2022}}. La représentativité est un élément clé de ces corpus restreints, qui doivent à leur échelle comporter suffisamment de cas d'études différents pour englober les situations rencontrées dans le corpus global, et ainsi produire un modèle apte à appréhender toutes les situations rencontrées dans un contexte d'inférence. Un dialogue entre les chercheurs et les ingénieurs est alors nécessaire, pour établir les besoins d'un point de vue technique comme d'un point de vue scientifique, afin d'obtenir en finalité un outil performant, apte à traiter le corpus du projet. Les chercheurs ayant une connaissance scientifique de la typologie des sources rencontrées dans le cadre du projet, ils sont ainsi à même d'estimer la diversité des images que rencontrera le modèle, et donc de construire un jeu de données d'entraînement représentatif et pertinent, en accord avec les bornes définies du projet.

Le projet \eida, dont le cadre géographique s'étend de l'Europe à l'Asie, du \viii au \xviii siècle, est ainsi vaste en termes de sources historiques et de diagrammes représentés. Les jeux de données d'entraînement doivent être représentatifs d'un point de vue thématique, en proposant des diagrammes aux formats et apparences diverses, en accord avec les typologies variées retrouvées dans le corpus ; mais ceux-ci doivent aussi prendre en compte la diversité des supports. Le corpus d'\eida comporte en effet des sources manuscrites comme des sources imprimées, qu'il est donc nécessaire de traiter conjointement. Il a été envisagé, pour des questions de performance, de produire un modèle de vision entraîné spécifiquement sur des sources manuscrites, et un second modèle entraîné sur des sources imprimées, afin de dissocier totalement le traitement de ces deux supports dans l'application finale\footnote{L'entraînement des modèles de détection d'objet n'ayant pas encore été effectué, il est actuellement impossible de tirer des conclusions quant à la pertinence de ce choix.}. Dans un corpus aussi varié linguistiquement que celui du projet \eida, il est également crucial de sélectionner un jeu de données d'entraînement diversifié du point de vue des langues, pour s'assurer de l'efficacité du modèle sur des sources aux provenances diverses : nous constatons en effet que les premières détections faites avec des modèles de détection pré-entraînés\footnote{Nous traitons de ces modèles dans la partie II.1.2.} sont satisfaisantes sur des sources latines ou grecques, mais qu'ils performent peu efficacement sur des sources chinoises, où chaque idéogramme est détecté comme une image.

Ainsi, l'automatisation d'une partie de la chaîne de traitement des sources permet, de construire un corpus de recherche vaste en offrant l'opportunité d'analyser un volume massif de sources historiques : ces possibilités sont particulièrement intéressante dans le cadre de projets de recherches inscrits dans l'histoire de la circulation des idées, des images et des théories, puisque les corpus construits peuvent être représentatifs de multiples cadres géographiques, temporels et thématiques, sans craindre un surplus de sources à traiter. Pour construire des outils pertinents pour le traitement de ces corpus massifs, il est cependant nécessaire d'avoir un regard global sur leur contenu, pour reproduire à moindre échelle leur représentativité dans des jeux de données d'entraînement, nécessaires au développement de modèles de vision artificielle pertinents pour des sources étudiées.
    
    \subsection{Automatiser le traitement de corpus massifs}
        \subsubsection{Possibilités de la \cv}
La vision artificielle offre, pour le traitement de ces larges corpus, la possibilité d'automatiser certaines étapes spécifiques qui interviennent en parallèle d'étapes d'analyse par les chercheurs. Il n'existe ainsi pas de \textit{workflow} totalement automatisée, où l'historien n'interviendrait pas dans le traitement des sources étudiées. En effet, l'intégration de la vision artificielle aux méthodes des historiens n'existe que conjointement à des interventions humaines, qui assurent la pertinence des traitements effectués et apportent une analyse nécessaire.

L'une des premières applications de la vision par ordinateur exploitée dans les projets étudiés est la détection d'objets dans les images : pour le traitement de sources numérisées, la détection d'objets présente des applications diverses. Il s'agit, le plus souvent, de la première étape d'une chaîne de traitement ; permettant, par exemple, dans l'étude de sources manuscrites ou imprimées contenant du texte et des illustrations, d'extraire les images présentes dans ces sources\footcite{buttnerCorDeepSacroboscoDataset2022}. Dans les projets \eida et \vhs, cette étape de détection des images dans les ouvrages est faite dans une optique de segmentation des pages, pour en extraire les illustrations qui seront ensuite traitées par d'autres algorithmes de vision, tels que des algorithmes de détection de similarité ou de vectorisation. D'autres projets, cependant, proposent dès l'étape de détection une classification des illustrations par typologie, pour permettre une première analyse et un premier regard sur la place de ces objets détectés dans les sources étudiées : l'application \textit{Cor}Deep\footcite{CorDeep}, développée par le Max Planck Institute for the History of Science en partenariat avec BIFOLD pour l'extraction d'éléments visuels dans les sources historiques, propose de classifier les illustrations détectées en quatre catégories\footnote{\textit{Content Illustrations}, \textit{Initials}, \textit{Decorations} et \textit{Printer's Marks}.}, appliquant dès la détection un premier traitement pour l'analyse des illustrations par les chercheurs, qui peuvent ainsi plus aisément naviguer des corpus de numérisations d'ouvrages par le biais des images.

La détection de similarité compte parmi les applications les plus directes du \dl\footcite{moiraghiExplorerCorpusImages2018} : il est possible, à l'aide d'un modèle entraîné sur un jeu de données restreint, d'effectuer sans supervision des comparaisons entre toutes les images du corpus, pour les réunir en séries ou groupes qui seront ensuite analysés par les historiens. Le développement d'un tel outil exemplifie les possibilités offertes par l'intelligence artificielle pour la navigation de gros corpus : elle permet de classifier les images en vue de leur étude en constituant des séries iconographiques aux caractéristiques visuelles similaires, selon un score de similarité calculé par l'algorithme. Dans le cas d'une étude des circulations des illustrations scientifiques, la constitution de ces séries permet aux chercheurs d'effectuer une analyse sur l'évolution des théories scientifiques, par le regroupement d'images de traditions différentes présentant des éléments similaires. L'automatisation de cette étape permet ainsi de tracer des parallèles entre un grand nombre d'image, en lançant la détection sur des corpus très larges qu'il serait difficile de traiter manuellement.

La \cv permet également d'envisager des traitements pour l'édition, et particulièrement dans le cas d'objets scientifiques tels que les diagrammes, dont la mise en forme est un questionnement à part entière pour l'édition des textes qu'ils illustrent. La détection de contours (ou \textit{edge detection}) est une étape fondamentale pour le traitement des images en vision artificielle : combinée à des méthodes de détection des lignes\footcite{linComprehensiveReviewImage2023}, il devient envisageable d'automatiser la transformation d'images au format .tiff ou .jpeg en objets plus aisément manipulables, et notamment la transformation vers le \svg, qui fait alors des diagrammes des objets édités et éditables, exploitables par les chercheurs en tant qu'objets numériques.

        \subsubsection{Diversité des traitements, diversité des données}

Pour ces divers traitements exploitant la vision artificielle, l'étape d'entraînement est nécessaire pour l'obtention d'un modèle efficace sur les données du projet, et pour que celui-ci performe en accord avec les tâches qui lui sont demandées. L'entraînement d'un modèle nécessite généralement plusieurs étapes\footcite{strienComputerVisionHumanities2022}, et par conséquent autant de jeux de données qu'il y a d'étapes : il est de bonne pratique de prévoir un jeu de données initial, et d'évaluer les performances du modèle après ce premier entraînement. À partir de ces résultats, il devient possible d'adapter les jeux de données suivants, pour pallier aux faiblesses constatées. De plus, si le format des données d'entraînement nécessaires varie en fonction des tâches effectuées par le modèle\footnote{Les cas varient en fonction du format des données d'entrée et de sortie : images au format .jpeg et annotations au format .txt pour la détection, images au format .jpeg et images au format .svg pour la vectorisation, etc.}, les exigences en termes de volume et de représentativité varient également. 

Pour des tâches classiques de vision artificielle, telles que la détection d'objets, des modèles pré-entraînés performants existent en libre accès, qui ne nécessitent donc pas autant de travail d'entraînement qu'un modèle créé dans son entièreté pour un projet. Des jeux de données en accès libre sont également disponibles pour l'entraînement de modèles pour la détection automatique, tels que ImageNet\footcite{ImageNet}, qui bien qu'ils ne soient pas adaptés à des sources historiques, permettent d'effectuer un premier entraînement d'un modèle sans mobiliser les moyens nécessaires à la création d'un jeu de données. Les algorithmes de détection de similarité ou de vectorisation, cependant, ne sont pas aussi développés que ces algorithmes de détection d'objets, et nécessitent donc un volume de données plus important, que les projets se doivent de fournir pour la création de modèles performants.

Ainsi, pour un projet d'humanités numériques faisant appel aux méthodes de la vision artificielle, il est nécessaire d'apporter une réflexion, en premier lieu, sur la pertinence de l'usage de l'\ia pour le traitement du corpus -- pertinence souvent relative au volume de données à traiter. Il est ensuite nécessaire, au-delà des sources du projet, de penser les données pour le \dl, en prenant en compte l'importance d'avoir des jeux de données qualitatifs et représentatifs pour la création d'un modèle efficace pour l'automatisation des tâches souhaitées. Les formats, typologies, volumes de ces jeux de données d'entraînement, souvent multiples, est ainsi à considérer en collaboration entre les équipes d'ingénierie et de recherche, pour prendre en considération les besoins vis-à-vis du contenu du corpus, tout en ne perdant pas de vue les besoins techniques liés à l'entraînement d'un modèle de vision par ordinateur.
